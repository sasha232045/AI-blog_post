難易度: 50

## 非線形回帰とは (Non-linear Regression)

**非線形回帰（ひせんけいかいき）**とは、統計学や機械学習で用いられる回帰分析の手法の一つで、一つまたは複数の説明変数と目的変数の間に、**直線ではない関係（非線形な関係）**を仮定して予測モデルを構築するアプローチの総称です。

### 非線形回帰が必要なとき

基本的な回帰モデルである**線形回帰**は、変数間の関係が「直線的」であると仮定します。例えば、「勉強時間が増えれば、テストの点数も一定の割合で伸びていく」といった関係です。

しかし、現実世界の現象は、必ずしもこのような単純な直線関係では説明できません。例えば、以下のようなケースが考えられます。

-   **効果が飽和するケース**: 「広告費を増やせば売上は伸びるが、ある一定の金額を超えると、その効果は次第に頭打ちになる」
-   **最適な値が存在するケース**: 「肥料の量が少なすぎても多すぎても作物の収穫量は減り、最適な量が存在する」

このような、曲線的な関係性を持つデータを無理やり直線で近似しようとすると、モデルの予測精度は著しく低下してしまいます。非線形回帰は、このような複雑なデータパターンをより柔軟に捉えるために用いられます。

### 主な非線形回帰の手法

非線形回帰には、様々なアルゴリズムが存在します。

1.  **多項式回帰 (Polynomial Regression)**
    最もシンプルで理解しやすい非線形回帰の一つです。説明変数の2乗、3乗といった**多項式項**をモデルに加えることで、曲線の関係を表現します。例えば、2次関数 `y = a*x^2 + b*x + c` を用いることで、放物線のようなデータパターンに適合させることができます。

2.  **サポートベクター回帰 (Support Vector Regression, SVR)**
    分類問題で高い性能を発揮する**サポートベクターマシン（SVM）**を、回帰問題に応用したものです。「マージン（余裕）」の概念を導入し、予測誤差が一定の範囲内に収まるような曲線を見つけ出します。

3.  **決定木回帰 (Decision Tree Regression)**
    データを「もし〜ならば〜」というルールに基づいて分割していく**決定木**アルゴリズムを回帰に応用したものです。データをいくつかの領域に分割し、各領域ごとに平均値などを予測値として出力します。これにより、階段状の非線形な関係を捉えることができます。

4.  **ニューラルネットワーク (Neural Network)**
    人間の脳の仕組みを模したモデルで、層を深くすることで、極めて複雑で高次元の非線形関係を学習する能力を持っています。現代のAI技術の中核をなすアプローチです。

### 線形回帰との使い分け

非線形回帰は表現力が高い一方で、モデルが複雑になりすぎる**過学習（Overfitting）**のリスクも高まります。つまり、訓練データに適合しすぎて、未知のデータに対する予測精度が逆に低下してしまう可能性があります。

そのため、まずはデータがどのような分布をしているかを可視化し、関係性が直線に近いと判断できれば、解釈も容易な線形回帰を試すのが一般的です。線形回帰ではうまく表現できないと判断された場合に、より複雑な非線形回帰モデルの適用を検討します。

### まとめ

非線形回帰は、単純な直線では捉えきれない、現実世界の多様で複雑な現象をモデル化するための強力なアプローチです。多項式回帰のようなシンプルなものから、ニューラルネットワークのような複雑なものまで、様々な手法をデータの特徴に応じて使い分けることで、より現実に即した、精度の高い予測を実現することができます。