難易度: 130

## 重み (Weight) とは

ニューラルネットワークにおける**重み (Weight)** とは、ネットワーク内のニューロン間の接続の**強さ**や**重要度**を調整するためのパラメータです。各接続はそれぞれ固有の重みを持っており、この重みの値を調整することによって、ニューラルネットワークは学習を行います。

しばしば「**重みパラメータ**」とも呼ばれます。

### 重みの役割：入力の重要度を調整する

人工ニューロンは、複数の前の層のニューロンから入力信号を受け取ります。このとき、各入力信号は、ニューロンに到達する前に、それぞれに対応する「重み」と掛け合わされます。

*   **重みが大きい（絶対値が大きい）**: その入力信号は、ニューロンの出力に対してより大きな影響を与えます。これは、その接続が「重要」であることを意味します。
*   **重みが小さい（絶対値が小さい）**: その入力信号は、ニューロンの出力に対してあまり影響を与えません。これは、その接続が「重要でない」ことを意味します。
*   **重みが正の値**: その入力信号は、ニューロンの発火を促進する（興奮させる）方向に働きます。
*   **重みが負の値**: その入力信号は、ニューロンの発火を抑制する（抑制する）方向に働きます。

例えば、住宅価格を予測するニューラルネットワークを考えてみましょう。「部屋の広さ」という入力に対応する重みは、おそらく大きな正の値になるでしょう。なぜなら、部屋が広いほど価格は高くなる傾向が強いからです。一方で、「近隣の騒音レベル」という入力に対応する重みは、負の値になるかもしれません。騒音が大きいほど、価格は下がる傾向があるからです。

### 学習とは「最適な重み」を見つけるプロセス

ニューラルネットワークの**学習**とは、一言で言えば、与えられたタスク（例: 画像認識、文章生成など）を最も上手く達成できるような、膨大な数の**重みパラメータの最適な組み合わせ**を見つけ出すプロセスです。

学習の初期段階では、重みはランダムな値に設定されています。そのため、ネットワークの出力は、全くのでたらめです。

ここから、**誤差逆伝播法 (Backpropagation)** などのアルゴリズムを用いて、以下のようなサイクルを何百万回と繰り返します。

1.  **予測**: 現在の重みを使って、入力データに対する予測を出力します。
2.  **誤差の計算**: 予測値と、実際の正解値との間の**誤差 (Error)** を計算します。
3.  **重みの更新**: 計算された誤差を基に、その誤差がより小さくなる方向へ、ネットワーク内の全ての重みをほんの少しだけ調整（更新）します。

このプロセスを通じて、ネットワークはデータの中に潜むパターンや特徴を、各ニューロン間の接続の「重み」という形で、徐々に学習していくのです。最終的に学習が完了したネットワークは、未知のデータに対しても、高い精度で正しい予測を行うことができるようになります。

### 重みとバイアスの違い

重みとよく似たパラメータに**バイアス (Bias)** があります。

*   **重み (Weight)**: 各**入力信号**の重要度を制御するパラメータ。
*   **バイアス (Bias)**: ニューロン自体の発火のしやすさ（感度）を制御するパラメータ。入力信号の総和に対して、最後に加算される固定値であり、ニューロンの基本的な活性化レベルを調整します。

両者はニューラルネットワークの挙動を決定する上で不可欠なパラメータであり、どちらも学習プロセスを通じて最適化されます。

### まとめ

重みは、ニューラルネットワークが知識を蓄積し、知的な振る舞いをするための、まさに「脳のシナプス」に相当する部分です。一つ一つの重みは単純な数値ですが、それらが何百万、何十億と集まって形成される巨大なネットワークが、今日の高度なAIの能力を支えています。ニューラルネットワークの学習とは、この膨大な重みパラメータを、データと計算の力によって彫刻していく、壮大な最適化の旅路であると言えるでしょう。